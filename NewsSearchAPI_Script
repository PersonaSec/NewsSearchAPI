#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Dec 19 15:52:24 2019

@author: EricTGonzalez
"""

# import requests to grab the url
import requests 
#use beautiful soup to pull out the resulting JSON file
from  bs4 import BeautifulSoup
# use pprint to organize the the JSON data cleanly - makes output easily readable
import pprint
#use pandas to organize the data into different categories for storing in a table
import pandas as pd
# used in conjunction with pandas
import numpy as np

#store the NewsApi url in the variable called url
url = 'https://newsapi.org/v2/everything?'
#store the NewsApi key in the secret variable
secret = 'e8307c205d23466e9daed66da20777ed'
# sets the query parameters
parameters = {
    'q': 'cory booker', # query phrase
    'pageSize': 20,  # maximum is 100
    'apiKey': secret, # your own API key
    'language' : 'en', # language
    'from' : '2019-11-19' # date - can only go back a month 
}
# stores the results of the query in the variable response
response = requests.get(url, params = parameters)
# converts the the query results into a JSON format and stores in response_json variable
response_json = response.json()
#prints and organizes the api pull results in JSON format
pprint.pprint(response_json)
"""prints the keys associated within the JSON file:
print (response_json.keys())  # pulling out the 'articles' key"""
# stores the articles key results in the articles variable
articles = response_json['articles']
# creates a dictionary that scrapes all of the info wanted from the articles key JSON file
def get_articles(file):
    article_results = []
    
    for i in range(len(file)):
        article_dict = {}
        article_dict['title'] = file[i]['title']
        article_dict['author'] = file[i]['author']
        article_dict['source'] = file[i]['source']
        article_dict['description'] = file[i]['description']
        article_dict['content'] = file[i]['content']
        article_dict['pub date'] = file[i]['publishedAt']
        article_dict['url'] = file[i]["url"]
        article_dict['pic url'] = file[i]['urlToImage']
        
        article_results.append(article_dict)
    return article_results
# creates a pandas dataframe of the query results
articles_df = pd.DataFrame(get_articles(articles))
# prints the shape of the data frame - serves as a Quality Control mechanism
print(articles_df.shape)
# converts the dataframe into a CSV
articles_df.to_csv('CbookerNews.csv', index = False)

